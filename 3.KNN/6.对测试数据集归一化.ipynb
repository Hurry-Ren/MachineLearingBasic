{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对训练数据集x_test求mean_train和std_train,然后用测试数据得到测试方差归一化（即：(x_test - mean_train) / std_train ）\n",
    "\n",
    "为什么不是求mean_test和std_test? \n",
    "    答：测试数据是模拟真实环境 \n",
    "        1.真实环境很可能无法得到所以测试数据的均值和方差。\n",
    "        （因为x_test的数据是不一定的，有时只有一个，不好求mean_test和std_test。）\n",
    "        2.对数据的归一化也是算法的一部分。(全部的数据都可以使用这个公式，测试数据也一样)\n",
    "因此，需要保存训练数据集得到的均值和方差。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-learn中的scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #分割训练和测试数据\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scikit-learn中的StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "\n",
    "standardScaler.fit(X_train) #存放了数据归一化的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.83416667, 3.08666667, 3.70833333, 1.17      ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardScaler.mean_ #均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81019502, 0.44327067, 1.76401924, 0.75317107])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardScaler.scale_ #方差 (std_ 已经过期了)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = standardScaler.transform(X_train) #把训练数据归一化\n",
    "X_test_standard = standardScaler.transform(X_test) #把测试数据也归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_clf.fit(X_train, y_train) #训练模型\n",
    "knn_clf.score(X_test_standard, y_test) #测试精确度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用自行实现的StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "votes =  <bound method Counter.most_common of Counter({1: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({2: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({1: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({2: 2, 1: 1})>\n",
      "votes =  <bound method Counter.most_common of Counter({0: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({1: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({1: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({2: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({1: 2, 2: 1})>\n",
      "votes =  <bound method Counter.most_common of Counter({1: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({1: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({0: 2, 1: 1})>\n",
      "votes =  <bound method Counter.most_common of Counter({0: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({0: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({2: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({1: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({0: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({2: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({2: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({2: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({1: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({0: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({2: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({0: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({1: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({1: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({0: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({1: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({2: 3})>\n",
      "votes =  <bound method Counter.most_common of Counter({2: 3})>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np #导入数据\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "from model_selection import train_test_split #切分数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, seed=666)\n",
    "\n",
    "from preprocessing import StandardScaler #对数据归一化处理，这里用的是均值方差归一化\n",
    "standardScaler2 = StandardScaler()\n",
    "standardScaler2.fit(X_train)\n",
    "X_train = standardScaler2.tranform(X_train) #别忘了这两步是关键\n",
    "X_test_standard = standardScaler2.tranform(X_test)\n",
    "\n",
    "\n",
    "from kNN import KNNClassifier #knn近邻\n",
    "knn_clf = KNNClassifier(3)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "knn_clf.accuracy_score(X_test_standard, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在sklearn.preprocessing.MinMaxScaler是最值归一化的方法，可以调用，也可以自己写 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结: k近邻算法有优点：1.可以解决多分类问题 2.思想简单，效果强大 \n",
    "               缺点：1.效率低下(如果训练集有m个样本，n个特征，则预测每一个新的数据需要O(m*n)),\n",
    "                        对应的优化可以使用树结构：KD-Tree,Ball-Treem\n",
    "                    2.得出的结果高度相关（如使用3-近邻算法，一旦周边有两个值出错时，结果就很可能出错了）\n",
    "                    3.预测结果不具有可解释性（只知道这个样本属于这个类别，但为什么属于这个类别则不知道）\n",
    "                    4.维数灾难（‘看似相近’的两个点之间的距离越来越大。如：0到1的距离在一维为1，在64维为8，\n",
    "                                在10000维为 100） 解决办法是：降维（PCA）\n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
